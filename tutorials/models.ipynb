{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models in PyTorch\n",
    "\n",
    "This notebook is a tutorial accompying the manuscript \"Perspectives: Comparison of Deep Learning Based Segmentation Models on Typical Biophysics and Biomedical Data\" by JS Bryan IV, M Tavakoli, and S Presse. In this tutorial, we will learn the basics of using the `nn.Module` class in PyTorch with prebuilt and custom layers.\n",
    "\n",
    "**Before reading this tutorial, make sure you have properly installed PyTorch and downloaded the data as explained in this repository's README.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the tutorial on models in PyTorch! In this tutorial, we will learn how to create models in PyTorch using the `nn.Module` class. We will also learn how to use prebuilt layers and create custom layers. The specific aim of this tutorial is the explain the models used in the accompanying manuscript, which can be found in the `models/` directory of this repository.\n",
    "\n",
    "Models in PyTorch are a convenient way to package together a neural network architecture. The `nn.Module` class is the base class for all models in PyTorch. It provides a convenient way to define the forward pass of a neural network, which is the process of passing input data through the network to get an output. The `nn.Module` class also provides a way to define the parameters of the network, which are the weights and biases that are learned during training.\n",
    "\n",
    "### Importing libraries\n",
    "\n",
    "Before we start, let's import the necessary libraries. We will be using the `torch` and `torch.nn` modules from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of nn.Module\n",
    "\n",
    "The Module class is the core of model creation in PyTorch. It provides a simple way to set up the parameters of the network and define the operations that are performed on the input data. The Module class has two main methods that need to be implemented: `__init__` and `forward`. The `__init__` method is used to define the layers and parameters of the network, while the `forward` method specifies how the input data is processed through these layers to produce the output.\n",
    "\n",
    "Lets start by creating a very simple model that simply scales and shifts the input data. To do this we will create a custom module called `ScaleShift` that inherits from `nn.Module`. In the `__init__` method, we will initialize the parent class of `ScaleShift` then define two parameters `scale` and `shift` that will be learned during training. Notice that to define parameters in a module, we use the `nn.Parameter` class. The `nn.Parameter` class is a wrapper around a tensor that tells PyTorch that this tensor should be treated as a parameter of the network during training. In the `forward` method, we will apply the scaling and shifting operations to the input data. Lastly we apply our custom module to some input data to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Output:  tensor([-0.3858, -0.2925, -0.1991, -0.1058, -0.0125,  0.0808,  0.1741,  0.2674,\n",
      "         0.3607,  0.4541], grad_fn=<AddBackward0>)\n",
      "Scale:  Parameter containing:\n",
      "tensor([0.0933], requires_grad=True)\n",
      "Shift:  Parameter containing:\n",
      "tensor([-0.4791], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## Create simple model that simply scales and shifts data\n",
    "class ScaleShift(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaleShift, self).__init__()         # Call parent class constructor, this is required for model\n",
    "        self.scale = nn.Parameter(torch.rand(1))   # Create scale parameter, initialized to random value\n",
    "        self.shift = nn.Parameter(torch.randn(1))  # Create shift parameter, initialized to random value\n",
    "    def forward(self, x):\n",
    "        return x * self.scale + self.shift         # Return scaled and shifted data\n",
    "    \n",
    "# Instantiate model and data\n",
    "model = ScaleShift()\n",
    "data = torch.linspace(1, 10, 10)\n",
    "\n",
    "# Run model on data\n",
    "output = model(data)\n",
    "\n",
    "# Print results\n",
    "print(\"Data: \", data)\n",
    "print(\"Output: \", output)\n",
    "print(\"Scale: \", model.scale)\n",
    "print(\"Shift: \", model.shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convenient part of using the `nn.Module` class is that it automatically handles the backpropagation of gradients through the network. This means that we don't have to manually calculate the gradients of the loss function with respect to the parameters of the network. PyTorch will automatically calculate these gradients for us using the `autograd` module.\n",
    "\n",
    "Additionally, the `nn.Module` we can call the forward method of the module directly on input data to get the output of the network. This is done by simply calling the module as if it were a function. For example we can call `output = model(input)` to get the output of the model on the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prebuilt Layers\n",
    "\n",
    "PyTorch provides a rich set of prebuilt layers in the torch.nn module, which makes it easy to build complex neural network architectures. These layers include convolutional layers, pooling layers, activation functions, and more. Using these prebuilt layers can save you time and ensure that your model components are optimized for performance. In this section, we will build a simple convolutional neural network (CNN) for image segmentation.\n",
    "\n",
    "Before we start, it's important to note that PyTorch models expect input tensors to have a batch dimension. This means that even if we are processing a single monocolor image, we need to structure our input as a 4D tensor with dimensions (batch, channel, height, width). This is important to keep in mind especially when loading data from files, where the channel dimension may be in a different order. Each layer has a different expected input shape, and it is important to read the [documentation](https://pytorch.org/docs/stable/index.html) for each layer to understand how to properly structure the input data.\n",
    "\n",
    "Now that we understand the basics of Modules and inputs, let us move onto creating our CNN. A simple model will consist of layers and blocks. Layers are individual components of the network, such as convolutional layers, pooling layers, and activation functions. Blocks are groups of layers that are repeated multiple times in the network. Our network will have three main blocks: an input block, a convolutional block, and an output block. Let us go over these in detail.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "Our model will have several attributes that define the architecture of the network. These attributes include the number of input channels, the number of feature channels, and the number of output channels. The number of input channels is the number of channels in the input data, which is typically 1 for grayscale images and 3 for color images. The number of feature channels is the number of channels in the intermediate feature maps of the network, which is a hyperparameter that can be tuned to control the capacity of the network. The number of output channels is the number of channels in the output data, which is typically the number of classes in a segmentation task.\n",
    "\n",
    "```python\n",
    "\n",
    "        # Set up attributes\n",
    "        self.in_channels = 3\n",
    "        self.out_channels = 2\n",
    "        self.n_features = 8\n",
    "\n",
    "```\n",
    "\n",
    "We specify 3 input channels for RGB images, 2 output channels for binary segmentation, and 8 feature channels for the intermediate feature maps of the network. These values can be adjusted depending on the specific task and dataset.\n",
    "\n",
    "### Input Block\n",
    "\n",
    "The input block is the first part of the network that preprocesses the input data. For our purposes, we need to normalize the input data to have zero mean and unit variance, and then add in additional feature channels so that the input data has the correct number of channels for the network. To do this we will use `nn.GroupNorm` to normalize the input data, and `nn.Conv2d` to add additional feature channels.\n",
    "\n",
    "```python\n",
    "\n",
    "        # Set up input block\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.GroupNorm(1, in_channels, affine=False),  # Normalize input\n",
    "            nn.Conv2d(in_channels, n_features, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "The `nn.GroupNorm` layer normalizes the input data to have zero mean and unit variance. The `nn.Conv2d` layer adds additional feature channels to the input data by applying a set of filters to the input data. The `kernel_size` parameter specifies the size of the filters, and the `padding` parameter specifies the amount of zero padding to add to the input data.\n",
    "\n",
    "Notice that we group layers together using the `nn.Sequential` class. This is a convenient way to define a sequence of layers in PyTorch. We can then call the `forward` method of the `nn.Sequential` object to apply the layers in sequence to the input data.\n",
    "\n",
    "### Convolutional Block\n",
    "\n",
    "The convolutional block is the main part of the network that processes the input data. A standard convolutional block consists of a convolutional layer, followed by a normalization layer, and finally an activation layer. The convolutional layer applies a set of filters to the input data to extract features. The normalization layer normalizes the output of the convolutional layer to stabilize the training process. The activation layer applies a non-linear function to the output of the normalization layer to introduce non-linearity into the network.\n",
    "\n",
    "```python\n",
    "\n",
    "        # Set up convolutional block\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(n_features),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "When we specify the parameters of `nn.Conv2d` the argument convention is `(in_channels, out_channels, kernel_size, padding)`. The `in_channels` parameter specifies the number of input channels to the convolutional layer, the `out_channels` parameter specifies the number of output channels, the `kernel_size` parameter specifies the size of the filters, and the `padding` parameter specifies the amount of zero padding to add to the input data.\n",
    "\n",
    "Notice that there are many different choices for normalization. Typically in the literature, batch normalization is used. However, in this model we use instance normalization. Instance normalization normalizes the output of the convolutional layer for each individual sample in the batch, which can be useful for style transfer and other tasks where the statistics of the output need to be preserved (i.e. where we do not want the output of the network to be affected by the statistics of the entire batch).\n",
    "\n",
    "Lastly, we use a Rectified Linear Unit (ReLU) activation function to introduce non-linearity into the network. The ReLU function applies the function `f(x) = max(0, x)` to the output of the normalization layer, which ensures that the output of the network is always positive. There are many other activation functions available in PyTorch, such as the sigmoid and tanh functions, but ReLU is the most commonly used activation function in deep learning.\n",
    "\n",
    "### Output Block\n",
    "\n",
    "The output block is the final part of the network that produces the output data. For our purposes, we need to convert the intermediate feature maps of the network into the final output data. To do this we will use `nn.Conv2d` to ensure that the output data has the correct number of channels.\n",
    "\n",
    "```python\n",
    "\n",
    "        # Set up output block\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Conv2d(n_features, out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "**One big consideration** There are many conventions for outputs of segmentation networks. We can choose to output the probability of each class for each pixel, or the logits of each class, or the class with the highest probability for each pixel. In this model, we output the logits of each class for each pixel. The logits are the raw output of the network before applying the softmax function, which converts the logits into probabilities. This is a common choice for segmentation networks, as it allows us to use the cross-entropy loss function to train the network. However, we must keep in mind that when we want to use our model for evaluation, we must apply the softmax function to the output to get the probabilities of each class.\n",
    "\n",
    "Lastly, one thing we should point out about output blocks is that in the code in the `models/` directory of this repository, we create a function, `set_output_block` to set the output block. This is because the number of output channels can change depending on the task. For example, in the manuscript, we use a model with 2 output channels for binary segmentation, and a model with 3 output channels for multiclass segmentation. By creating a separate function to set the output block, we can easily change the number of output channels without having to modify the rest of the model. This is beyond the scope of this tutorial and we will not cover it here.\n",
    "\n",
    "### Forward Method\n",
    "\n",
    "The `forward` method of the model specifies how the input data is processed through the network to produce the output. In our model, we apply the input block to the input data, then pass the output through the convolutional block multiple times, and finally apply the output block to produce the final output.\n",
    "\n",
    "```python\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply input block\n",
    "        x = self.input_block(x)\n",
    "\n",
    "        # Apply convolutional block\n",
    "        for _ in range(2):\n",
    "            x = self.conv_block(x)\n",
    "\n",
    "        # Apply output block\n",
    "        x = self.output_block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "### Putting it all together\n",
    "\n",
    "Now that we have defined the input block, convolutional block, and output block, we can put them all together to create the full model. We can do this by defining a new class called `SimpleCNN` that inherits from `nn.Module` and combines the input block, convolutional block, and output block into a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  tensor([[[[-1.1278, -0.0214, -0.5631,  ...,  0.7420, -0.1258,  0.7185],\n",
      "          [ 1.0944, -0.8027,  0.8063,  ...,  1.2051,  1.1187, -0.1114],\n",
      "          [ 1.5907,  0.5595, -1.9239,  ..., -0.8093, -0.9308, -0.2255],\n",
      "          ...,\n",
      "          [ 0.5830,  0.7052, -0.4028,  ..., -0.0998, -0.3303, -0.8037],\n",
      "          [ 0.1542,  0.6144, -0.1969,  ..., -1.2185, -0.1592, -1.3697],\n",
      "          [-0.8191,  0.4712,  0.5140,  ..., -0.2821, -2.1205,  1.7506]],\n",
      "\n",
      "         [[ 0.8654, -0.1745,  1.4989,  ..., -2.2217, -1.6593, -0.0299],\n",
      "          [ 0.3860,  0.8777,  0.0254,  ..., -1.7589, -0.9202, -0.4260],\n",
      "          [ 0.5673, -0.8840,  0.4599,  ..., -0.9532, -1.0387, -0.1461],\n",
      "          ...,\n",
      "          [ 0.6346, -0.0481,  0.4742,  ..., -0.2908,  0.3976,  1.1244],\n",
      "          [-1.9532, -0.4765,  0.2615,  ...,  1.1766, -0.0833,  0.2104],\n",
      "          [-1.0329,  0.0407, -1.8705,  ...,  1.5924, -2.2502, -1.8930]],\n",
      "\n",
      "         [[-0.6035,  1.1668, -0.2917,  ..., -1.2814, -1.4492,  0.4326],\n",
      "          [ 0.4711, -1.1111,  0.7601,  ...,  0.7756,  1.5422,  0.5450],\n",
      "          [-0.1439,  0.8275, -0.2870,  ...,  0.0951, -0.1093, -0.9644],\n",
      "          ...,\n",
      "          [ 1.4656,  1.3360, -0.8157,  ..., -1.5034,  0.1742, -2.0126],\n",
      "          [ 0.9489,  1.0976,  0.3162,  ...,  0.3558,  1.7536,  0.1293],\n",
      "          [-0.5509,  1.1597, -1.2564,  ...,  0.4271,  0.3072, -0.0564]]]])\n",
      "Output:  tensor([[[[ 0.7621,  0.6422,  0.5651,  ...,  0.3885,  0.3127,  0.0942],\n",
      "          [ 0.3665,  0.2205,  0.7873,  ...,  0.5787,  0.5500,  0.2919],\n",
      "          [ 0.8625,  0.4896,  0.4464,  ...,  0.4004,  0.7954,  0.2961],\n",
      "          ...,\n",
      "          [ 0.3126,  0.4022,  0.6301,  ...,  0.5721,  0.1527,  0.2616],\n",
      "          [ 0.4411,  0.9728,  0.4462,  ...,  0.6947,  0.8112,  0.1730],\n",
      "          [ 0.3518,  0.3884,  0.7137,  ...,  0.4682,  0.3355,  1.0957]],\n",
      "\n",
      "         [[ 0.0025, -0.1138,  0.2717,  ..., -0.1123, -0.2067, -0.1211],\n",
      "          [-0.0029, -0.0935,  0.0528,  ...,  0.2187, -0.0569, -0.2421],\n",
      "          [ 0.1016, -0.0738,  0.0617,  ..., -0.1540,  0.0325, -0.1087],\n",
      "          ...,\n",
      "          [-0.0257,  0.2732, -0.1158,  ..., -0.1084,  0.1217,  0.0876],\n",
      "          [-0.0833,  0.3740, -0.0541,  ...,  0.2115,  0.3126,  0.5372],\n",
      "          [-0.0935, -0.1134, -0.0100,  ..., -0.1499, -0.2550,  0.1518]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define the ConvolutionalNet class\n",
    "class ConvolutionalNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_features=8):\n",
    "        super(ConvolutionalNet, self).__init__()\n",
    "\n",
    "        # Set up attributes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_features = n_features\n",
    "\n",
    "\n",
    "        ### SET UP BLOCKS ###\n",
    "\n",
    "        # Set up input block\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.GroupNorm(1, in_channels, affine=False),  # Normalize input\n",
    "            nn.Conv2d(in_channels, n_features, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        # Set up layers\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(n_features),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Set up output block\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Conv2d(self.n_features, out_channels, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "\n",
    "        # Input block\n",
    "        x = self.input_block(x)\n",
    "\n",
    "        # Convolutional block\n",
    "        x = self.conv_block(x)\n",
    "\n",
    "        # Output block\n",
    "        x = self.output_block(x)\n",
    "\n",
    "        # Return\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Set up model and data\n",
    "model = ConvolutionalNet(3, 2, n_features=8)  # 3 input channels (RGB), 2 output channels, 8 features\n",
    "data = torch.randn(1, 3, 32, 32)              # 1 batch, 3 channels, 32x32 image\n",
    "\n",
    "# Run model on data\n",
    "output = model(data)\n",
    "\n",
    "# Print results\n",
    "print(\"Data: \", data)\n",
    "print(\"Output: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This covers all the basics of creating models in PyTorch. We have learned how to use the `nn.Module` class to define the architecture of a neural network, how to use prebuilt layers to build complex models, and how to create custom layers for specific tasks. We have also learned how to structure the input data for a neural network and how to define the forward pass of the network to produce the output. By following these steps, you can create your own models in PyTorch for a wide range of tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
